# Deepfake Detector Assessment Platform (DAP)

We have set up a project for evaluating deepfake detection. Users can upload detection algorithms, and the project will assess the performance of these algorithms in various aspects.

The main evaluation features of the project are shown in the following figure.

![image1](https://github.com/tempuser4567/DAP/tree/main/png/1.png)


## Dataset Introduction:

The dataset is primarily composed of three parts.: public datasets, self-constructed datasets and specially processed dataset. The public datasets include 11 open-source datasets. The self-constructed dataset is generated using deepfake algorithms and includes 3 face-swapping algorithms, 2 facial reenactment algorithms, 2 facial attribute manipulation algorithms, 4 entire face synthesis algorithms, 4 text-to-image algorithms, and 1 image-to-video algorithm, totaling 16 deepfake algorithms. The specially processed dataset is primarily generated using various data augmentation and adversarial evasion techniques. It is used to evaluate the robustness and security of detection algorithms.


### Public Dataset Introduction:

These public datasets include data from different deepfake algorithms, genders, ethnicities, expressions, lighting conditions, and camera angles, which can be used to evaluate the performance of detection algorithms in these specific areas. 

### Self-constructed Dataset Introduction:

The self-constructed datasets include data generated by diverse deepfake algorithms, which can be used to assess the generalization capability of detection algorithms.
The number of images generated by the forgery algorithm is shown in the table below.

| Index | Category                      | Algorithm | Number    |
| ----- | ----------------------------- | --------- | --------- |
| 1     | Face Swapping                 | XXX       | 596,416   |
| 2     | Face Swapping                 | XXX       | 670,682   |
| 3     | Face Swapping                 | XXX       | 606,953   |
| 4     | Facial Reenactment            | XXX       | 941,082   |
| 5     | Facial Reenactment            | XXX       | 576,142   |
| 6     | Facial Attribute Manipulation | XXX       | 420,000   |
| 7     | Facial Attribute Manipulation | XXX       | 1,215,821 |
| 8     | Entire Face Synthesis         | XXX       | 100,000   |
| 9     | Entire Face Synthesis         | XXX       | 100,000   |
| 10    | Entire Face Synthesis         | XXX       | 100,000   |
| 11    | Entire Face Synthesis         | XXX       | 240,000   |
| 12    | Text-to-Image                 | XXX       | 120,552   |
| 13    | Text-to-Image                 | XXX       | 82,982    |
| 14    | Text-to-Image                 | XXX       | 4,445     |
| 15    | Text-to-Image                 | XXX       | 100,000   |
| 16    | Image-to-Video                | XXX       | 101,070   |



![image2](https://github.com/tempuser4567/DAP/tree/main/png/2.png)

### Specially Processed Dataset Introduction:

To test the robustness of the detection algorithm on augmented data, We have implemented several data augmentation algorithms, such as adjusting image brightness, contrast, hue, sharpness, rotation, blurring, and occlusion, to evaluate the robustness of detection algorithms. 

Additionally, we have configured adversarial (adding adversarial noise) and evasion (image reconstruction) algorithms to assess the security of detection algorithms when faced with malicious adversarial and evasion techniques.

![image3](https://github.com/tempuser4567/DAP/tree/main/png/3.png)

### Data Composition: 

Our data consists of three levels: video-level, frame-level, and face-level. The latter two are obtained by extracting frames and faces from the original videos, respectively, and are used to evaluate detection algorithms that target different inputs. The overall data structure is as follows:

```text
datasets
├── FaceForensics++
│ ├── original_sequences
│ │ ├── youtube
│ │ │ ├── c23
│ │ │ │ ├── videos
│ │ │ │ │ └── *.mp4
│ │ │ │ └── frames
│ │ │ │ │ └── *.png
│ │ │ │ └── faces
│ │ │ │ │ └── *.png
│ │ │ └── c40
│ │ │ │ ├── ...
│ │ ├── actors
│ │ │ ├── ...
│ ├── manipulated_sequences
│ │ ├── Deepfakes
│ │ │ ├── c23
│ │ │ │ └── videos
│ │ │ │ │ └── *.mp4
│ │ │ │ └── frames
│ │ │ │ │ └── *.png
│ │ │ └── c40
│ │ │ │ ├── ...
│ │ ├── Face2Face
│ │ │ ├── ...
│ │ ├── FaceSwap
│ │ │ ├── ...
│ │ ├── NeuralTextures
│ │ │ ├── ...
│ │ ├── FaceShifter
│ │ │ ├── ...
│ │ └── DeepFakeDetection
│ │ ├── ...
```
Other datasets are similar to the above structure



Our label structures are as follows:

```
datasets
├── FaceForensics++
│ ├── videos
│ │ ├── attribute
│ │ │ └── FaceForensics++_fake_DeepFakeDetection_c23_videos.txt
│ │ │ └── FaceForensics++_real_actors_c23_videos.txt
│ │ │ └── ...
│ │ └── FaceForensics++_real_videos.txt
│ │ └── FaceForensics++_fake_videos.txt
│ ├── frames
│ │ ├── ...
│ ├── faces
│ │ ├── ...
```

The attributes folder contains data labels that provide detailed categorization based on specific attributes such as forgery methods, ethnicity, gender, and other characteristics.


### Test Annotations:

For evaluating detection algorithms, we select 10,000 real images and 10,000 forged images from the corresponding datasets for result testing.

The specific test items and the corresponding datasets are shown in the table below:

| Test Content                   | Dataset                                   |
| ------------------------------ | ----------------------------------------- |
| Effectiveness Testing          | All public datasets                       |
| Specific Attribute Testing     | Datasets with corresponding label files   |
| Generalization Testing         | All self-constructed datasets             |
| Robustness Testing             | Robustness processed dataset              |
| Security Testing               | Adversarial and evasion processed dataset |
| Specific Functionality Testing | Datasets with corresponding label files   |

The test content and metrics are as follows:

Effectiveness Testing: The test evaluates the basic performance metrics of detection algorithms on a general dataset, including AUC, ACC, EER, F1/F2-score, confidence, and other indicators.

Specific Attribute Testing: The test assesses the detection capability on datasets with specific attributes.   (??? test metrics)

Generalization Testing: The test evaluates the generalization capability of detection algorithms.

Robustness Testing: The test assesses the robustness of detection algorithms when faced with traditional data modifications and enhancements.

Security Testing: The test evaluates the detection capability of algorithms when facing malicious evasion and attack forgery data.

Specific Functionality Testing: The test evaluates the special functionalities of detection algorithms, if they exist, such as forged region localization, fragment forgery detection, etc.



## Algorithms Introduction

We have configured some forgery algorithms and detection algorithms. Forgery algorithms are used to generate data (see the introduction in the self-constructed dataset section), while detection algorithms are used to test metrics and provide baselines for existing detection algorithms. Currently, we have configured 10 forgery algorithms, listed as follows.

| ID   | name               | function                             |
| ---- | ------------------ | ------------------------------------ |
| 1    | Xception           | Detection of forged face-level data  |
| 2    | SRM                | Detection of forged face-level data  |
| 3    | SBI                | Detection of forged face-level data  |
| 4    | DSP_FWA            | Detection of forged face-level data  |
| 5    | Multiple-attention | Detection of forged face-level data  |
| 6    | SeqDeepFake        | Detection of forged face-level data  |
| 7    | SLADD              | Detection of forged face-level data  |
| 8    | CADDM              | Detection of forged frame-level data |
| 9    | Multiple-attention | Detection of forged video-level data |
| 10   | ClassNSeg          | Detecting forged regions             |
| 11   | BA-TFD             | Detecting forged segments            |

## Presentation of Results
